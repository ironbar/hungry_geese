{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Explore-other-reward-functions\" data-toc-modified-id=\"Explore-other-reward-functions-1\">Explore other reward functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Goal\" data-toc-modified-id=\"Goal-1.1\">Goal</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.2\">Imports</a></span></li><li><span><a href=\"#Ranking-reward\" data-toc-modified-id=\"Ranking-reward-1.3\">Ranking reward</a></span><ul class=\"toc-item\"><li><span><a href=\"#Generate-games\" data-toc-modified-id=\"Generate-games-1.3.1\">Generate games</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-1.3.1.1\">Code</a></span></li><li><span><a href=\"#Generation\" data-toc-modified-id=\"Generation-1.3.1.2\">Generation</a></span></li></ul></li></ul></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Explore other reward functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebooks is to continue learning about the Q value function, but trying other reward methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:26:21.934328Z",
     "start_time": "2021-03-13T12:26:21.915223Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use this to reload changes in python scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:26:23.169932Z",
     "start_time": "2021-03-13T12:26:21.936423Z"
    },
    "hidden": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading environment football failed: No module named 'gfootball'\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import kaggle_environments\n",
    "from kaggle_environments import make\n",
    "from kaggle_environments import evaluate\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from itertools import permutations\n",
    "from functools import partial\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from hungry_geese import GameState\n",
    "from hungry_geese.state import make_board_egocentric, get_head_position, combine_data, horizontal_simmetry, vertical_simmetry\n",
    "from hungry_geese.utils import ACTIONS, opposite_action, get_timestamp\n",
    "from hungry_geese.definitions import ACTION_TO_IDX\n",
    "from hungry_geese.agents import EpsilonAgent\n",
    "from hungry_geese.evaluation import play_matches_in_parallel, monitor_progress\n",
    "from hungry_geese.elo import EloRanking\n",
    "from hungry_geese.model import simple_model, create_model_for_training\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:26:23.203036Z",
     "start_time": "2021-03-13T12:26:23.171769Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (30, 5)  \n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ranking reward"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate games"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:26:23.227114Z",
     "start_time": "2021-03-13T12:26:23.204522Z"
    }
   },
   "outputs": [],
   "source": [
    "from concurrent.futures import ProcessPoolExecutor\n",
    "\n",
    "def play_matches_in_parallel_and_save_history(agents, max_workers=20, n_matches=1000,\n",
    "                                              running_on_notebook=True):\n",
    "    \"\"\"\n",
    "    Plays n_matches in parallel using ProcessPoolExecutor\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    agents : dict\n",
    "        Dictionary that matches name of the agents with the code\n",
    "    sample_agents_func : func\n",
    "        Function that returns random keys of the agents for playing a game\n",
    "    \"\"\"\n",
    "    pool = ProcessPoolExecutor(max_workers=max_workers)\n",
    "    matches_results = []\n",
    "    submits = []\n",
    "    for i in range(n_matches):\n",
    "        submits.append(pool.submit(play_game, agents=agents))\n",
    "    monitor_progress(submits, running_on_notebook)\n",
    "    matches_results = [submit.result() for submit in submits]\n",
    "    return matches_results\n",
    "\n",
    "def play_game(agents):\n",
    "    env = make(\"hungry_geese\")\n",
    "    return env.run(agents=agents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:26:23.247772Z",
     "start_time": "2021-03-13T12:26:23.228513Z"
    }
   },
   "outputs": [],
   "source": [
    "def test_agent(agent):\n",
    "    print('Testing agent: %s' % agent)\n",
    "    env = make('hungry_geese', debug=True)\n",
    "    env.run([agent]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:26:23.270964Z",
     "start_time": "2021-03-13T12:26:23.248931Z"
    }
   },
   "outputs": [],
   "source": [
    "def create_train_data(agents, n_matches, output_file, reward_name, max_workers=18):\n",
    "    \"\"\"\n",
    "    Creates train data without any simmetry\n",
    "    \"\"\"\n",
    "    test_agent(agents[0])\n",
    "    matches_results = play_matches_in_parallel_and_save_history(\n",
    "        agents, n_matches=n_matches, max_workers=max_workers)\n",
    "    \n",
    "    env = make(\"hungry_geese\")\n",
    "    conf = env.configuration\n",
    "\n",
    "    state = GameState(reward_name=reward_name)\n",
    "    train_data = []\n",
    "\n",
    "    for match in tqdm(matches_results):\n",
    "        for idx in range(4):\n",
    "            state.reset()\n",
    "            for step_idx, step in enumerate(match):\n",
    "                observation = step[0]['observation'].copy()\n",
    "                observation['index'] = idx\n",
    "                state.update(observation, conf)\n",
    "                if step_idx:\n",
    "                    state.add_action(step[idx]['action'])\n",
    "                if not observation['geese'][idx]:\n",
    "                    break\n",
    "            train_data.append(state.prepare_data_for_training())\n",
    "\n",
    "    train_data = combine_data(train_data)\n",
    "    print('Size of the boards is %.1f GB' % (train_data[0].nbytes/1e9))\n",
    "    os.makedirs(os.path.dirname(output_file), exist_ok=True)\n",
    "    np.savez_compressed(output_file, boards=train_data[0], features=train_data[1], actions=train_data[2], rewards=train_data[3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-03-13T12:26:25.056132Z",
     "start_time": "2021-03-13T12:26:23.272593Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing agent: /mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/forum/agents/random_plus.py\n",
      "Goose Collision: EAST\n",
      "Goose Collision: NORTH\n",
      "Goose Starved: Action.SOUTH\n",
      "Goose Starved: Action.WEST\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db9b8e638b654b9fa817a3f99832d3d7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "49b2a7a082094963bb1d32de6988e07f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "No loop matching the specified signature and casting was found for ufunc true_divide",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-784112a8dcdc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mreward_name\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'ranking_reward_-5_2'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0moutput_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'/mnt/hdd0/Kaggle/hungry_geese/data/%s/%s_matches_%i.npz'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mreward_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbasename\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_matches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mcreate_train_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0magents\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_matches\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mn_matches\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_file\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mreward_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_workers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m18\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-6-3c3f2fd0789b>\u001b[0m in \u001b[0;36mcreate_train_data\u001b[0;34m(agents, n_matches, output_file, reward_name, max_workers)\u001b[0m\n\u001b[1;32m     24\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mobservation\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'geese'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m                     \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m             \u001b[0mtrain_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprepare_data_for_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m     \u001b[0mtrain_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcombine_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/hungry_geese/state.py\u001b[0m in \u001b[0;36mprepare_data_for_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    103\u001b[0m             \u001b[0mCumulative\u001b[0m \u001b[0mreward\u001b[0m \u001b[0mreceived\u001b[0m \u001b[0mduring\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mepisode\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msteps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m         \"\"\"\n\u001b[0;32m--> 105\u001b[0;31m         \u001b[0mcumulative_reward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_cumulative_reward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreward_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    106\u001b[0m         \u001b[0mactions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mactions\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcumulative_reward\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mACTION_TO_IDX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/hungry_geese/reward.py\u001b[0m in \u001b[0;36mget_cumulative_reward\u001b[0;34m(rewards, reward_name)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0mcumulative_reward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m         \u001b[0mcumulative_reward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mwindow_size\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0mwindow_size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwindow_size\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mcumulative_reward\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m/=\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: No loop matching the specified signature and casting was found for ufunc true_divide"
     ]
    }
   ],
   "source": [
    "n_matches = 10\n",
    "agents = ['/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/forum/agents/random_plus.py']*4\n",
    "reward_name = 'ranking_reward_-5_2'\n",
    "output_file = '/mnt/hdd0/Kaggle/hungry_geese/data/%s/%s_matches_%i.npz' % (reward_name, os.path.splitext(os.path.basename(agents[0]))[0], n_matches)\n",
    "create_train_data(agents=agents, n_matches=n_matches, output_file=output_file, reward_name=reward_name, max_workers=18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (goose)",
   "language": "python",
   "name": "goose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

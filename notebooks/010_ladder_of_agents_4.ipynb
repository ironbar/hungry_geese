{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Train-models-after-great-redesign\" data-toc-modified-id=\"Train-models-after-great-redesign-1\">Train models after great redesign</a></span><ul class=\"toc-item\"><li><span><a href=\"#Goal\" data-toc-modified-id=\"Goal-1.1\">Goal</a></span></li><li><span><a href=\"#Imports\" data-toc-modified-id=\"Imports-1.2\">Imports</a></span></li><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-1.3\">Code</a></span><ul class=\"toc-item\"><li><span><a href=\"#Data-generation\" data-toc-modified-id=\"Data-generation-1.3.1\">Data generation</a></span></li><li><span><a href=\"#Evaluation\" data-toc-modified-id=\"Evaluation-1.3.2\">Evaluation</a></span></li><li><span><a href=\"#Visualization\" data-toc-modified-id=\"Visualization-1.3.3\">Visualization</a></span></li></ul></li><li><span><a href=\"#Agent-evaluation\" data-toc-modified-id=\"Agent-evaluation-1.4\">Agent evaluation</a></span><ul class=\"toc-item\"><li><span><a href=\"#Bug-fix-agent-change\" data-toc-modified-id=\"Bug-fix-agent-change-1.4.1\">Bug fix agent change</a></span></li><li><span><a href=\"#Reevaluate-frozen-agents\" data-toc-modified-id=\"Reevaluate-frozen-agents-1.4.2\">Reevaluate frozen agents</a></span></li><li><span><a href=\"#New-agents\" data-toc-modified-id=\"New-agents-1.4.3\">New agents</a></span></li></ul></li><li><span><a href=\"#Visualizing-agent-play\" data-toc-modified-id=\"Visualizing-agent-play-1.5\">Visualizing agent play</a></span><ul class=\"toc-item\"><li><span><a href=\"#40_study_effect_of_epsilon/04_epsilon_greedy_001\" data-toc-modified-id=\"40_study_effect_of_epsilon/04_epsilon_greedy_001-1.5.1\">40_study_effect_of_epsilon/04_epsilon_greedy_001</a></span></li></ul></li><li><span><a href=\"#Study-train-data-to-create-new-metrics\" data-toc-modified-id=\"Study-train-data-to-create-new-metrics-1.6\">Study train data to create new metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Code\" data-toc-modified-id=\"Code-1.6.1\">Code</a></span></li><li><span><a href=\"#First-explorations\" data-toc-modified-id=\"First-explorations-1.6.2\">First explorations</a></span></li><li><span><a href=\"#Match-visualization\" data-toc-modified-id=\"Match-visualization-1.6.3\">Match visualization</a></span></li></ul></li><li><span><a href=\"#Study-game-data-after-improving-certain-death-reward\" data-toc-modified-id=\"Study-game-data-after-improving-certain-death-reward-1.7\">Study game data after improving certain death reward</a></span></li><li><span><a href=\"#Useful-snippets\" data-toc-modified-id=\"Useful-snippets-1.8\">Useful snippets</a></span></li><li><span><a href=\"#Summary\" data-toc-modified-id=\"Summary-1.9\">Summary</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train models after great redesign"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebooks is to hopefully do the last steps with Q* learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:10:58.897561Z",
     "start_time": "2021-06-05T14:10:58.881230Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "# Use this to reload changes in python scripts\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.462245Z",
     "start_time": "2021-06-05T14:10:58.899387Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import kaggle_environments\n",
    "from kaggle_environments import make\n",
    "from kaggle_environments import evaluate\n",
    "from kaggle_environments.envs.hungry_geese.hungry_geese import Action\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "import random\n",
    "import pandas as pd\n",
    "from tqdm.notebook import tqdm\n",
    "import time\n",
    "from itertools import permutations\n",
    "from functools import partial\n",
    "import gc\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import json\n",
    "import logging\n",
    "import glob\n",
    "from IPython.display import clear_output\n",
    "import tempfile\n",
    "import yaml\n",
    "import seaborn as sns\n",
    "\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "#os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "from hungry_geese import GameState\n",
    "from hungry_geese.state import make_board_egocentric, get_head_position, combine_data, horizontal_simmetry, vertical_simmetry\n",
    "from hungry_geese.utils import ACTIONS, opposite_action, get_timestamp, log_ram_usage, configure_logging\n",
    "from hungry_geese.definitions import ACTION_TO_IDX\n",
    "from hungry_geese.agents import EpsilonAgent, QValueAgent, SoftmaxAgent, QValueSafeAgent, QValueSemiSafeAgent\n",
    "from hungry_geese.evaluation import play_matches_in_parallel, monitor_progress\n",
    "from hungry_geese.elo import EloRanking\n",
    "from hungry_geese.model import simple_model, create_model_for_training\n",
    "\n",
    "%config Completer.use_jedi = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.498599Z",
     "start_time": "2021-06-05T14:11:00.463752Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "plt.plot()\n",
    "plt.close('all')\n",
    "plt.rcParams[\"figure.figsize\"] = (30, 5)  \n",
    "mpl.rcParams['lines.linewidth'] = 3\n",
    "mpl.rcParams['font.size'] = 16\n",
    "\n",
    "configure_logging(logging.INFO)\n",
    "logger = logging.getLogger(__name__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Data generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.522943Z",
     "start_time": "2021-06-05T14:11:00.499971Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def play_matches_in_parallel_and_save_history(agents, max_workers=20, n_matches=1000,\n",
    "                                              output_path=None,\n",
    "                                              running_on_notebook=True):\n",
    "    \"\"\"\n",
    "    Plays n_matches in parallel using ProcessPoolExecutor\n",
    "\n",
    "    Parameters\n",
    "    -----------\n",
    "    agents : list\n",
    "        List of the agents that we will use for playing\n",
    "    \"\"\"\n",
    "    log_ram_usage()\n",
    "    output_path = output_path or get_games_output_path(agents, n_matches)\n",
    "    assert not os.path.exists(output_path), 'Output path already exists: %s' % output_path\n",
    "    with ProcessPoolExecutor(max_workers=max_workers) as pool:\n",
    "        matches_results = []\n",
    "        submits = []\n",
    "        for i in range(n_matches):\n",
    "            if isinstance(agents, list):\n",
    "                submits.append(pool.submit(play_game, agents=agents))\n",
    "            elif callable(agents):\n",
    "                submits.append(pool.submit(play_game, agents=agents()))\n",
    "            else:\n",
    "                raise TypeError(type(agents))\n",
    "        monitor_progress(submits, running_on_notebook)\n",
    "        matches_results = [submit.result() for submit in submits]\n",
    "    \n",
    "    log_ram_usage()\n",
    "    logger.info('saving matches to json: %s' % output_path)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(matches_results, f)\n",
    "        \n",
    "    del submits\n",
    "    del matches_results\n",
    "    gc.collect()\n",
    "    log_ram_usage()\n",
    "\n",
    "def play_game(agents):\n",
    "    env = make(\"hungry_geese\")\n",
    "    return env.run(agents=agents)\n",
    "\n",
    "def get_games_output_path(agents, n_matches):\n",
    "    output_path = '/mnt/hdd0/Kaggle/hungry_geese/games/%s_vs_%s_matches_%i.json' % (\n",
    "        os.path.splitext(os.path.basename(agents[0]))[0], \n",
    "        os.path.splitext(os.path.basename(agents[1]))[0], \n",
    "        n_matches)\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.543612Z",
     "start_time": "2021-06-05T14:11:00.524084Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def test_agent(agent):\n",
    "    print('Testing agent: %s' % agent)\n",
    "    env = make('hungry_geese', debug=True)\n",
    "    env.run([agent]*4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.583869Z",
     "start_time": "2021-06-05T14:11:00.545820Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_train_data_from_saved_matches(saved_games_paths, reward_name, output_path, agent_idx_range=None):\n",
    "    \"\"\"\n",
    "    Creates train data without any simmetry\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    saved_games_paths : list of str\n",
    "        Path to the games that we want to use\n",
    "    reward_name : str\n",
    "        Name of the reward function that we want to use\n",
    "    output_path : str\n",
    "        Path to the file were we are going to save the results\n",
    "    max_workers : int\n",
    "    agent_idx_range : list of int\n",
    "        Idx of the agents we want to use for collecting data, if None all the agents\n",
    "        will be used\n",
    "    \"\"\"\n",
    "    env = make(\"hungry_geese\")\n",
    "    conf = env.configuration\n",
    "\n",
    "    state = GameState(reward_name=reward_name)\n",
    "    train_data = []\n",
    "    agent_idx_range = agent_idx_range or list(range(4))\n",
    "    \n",
    "    for saved_games_path in tqdm(saved_games_paths, desc='looping over saved games'):\n",
    "        log_ram_usage()\n",
    "        with open(saved_games_path, 'r') as f:\n",
    "            matches_results = json.load(f)\n",
    "        log_ram_usage()\n",
    "    \n",
    "        for _ in tqdm(range(len(matches_results)), desc='Creating game data'):\n",
    "            match = matches_results[0]\n",
    "            for idx in agent_idx_range:\n",
    "                state.reset()\n",
    "                for step_idx, step in enumerate(match):\n",
    "                    observation = step[0]['observation'].copy()\n",
    "                    observation['index'] = idx\n",
    "                    state.update(observation, conf)\n",
    "                    if step_idx:\n",
    "                        state.add_action(step[idx]['action'])\n",
    "                    if not observation['geese'][idx]:\n",
    "                        break\n",
    "                train_data.append(state.prepare_data_for_training())\n",
    "            del matches_results[0]\n",
    "        \n",
    "    log_ram_usage()\n",
    "    logger.info('Going to combine the data')\n",
    "    train_data = combine_data(train_data)\n",
    "    log_ram_usage()\n",
    "    logger.info('Size of the boards is %.1f GB (%s [%.1f GB])' % (\n",
    "        train_data[0].nbytes/1e9,\n",
    "        str([round(data.nbytes/1e9, 1) for data in train_data]),\n",
    "        np.sum([data.nbytes/1e9 for data in train_data])))\n",
    "    logger.info('Saving data on: %s' % output_path)\n",
    "    os.makedirs(os.path.dirname(output_path), exist_ok=True)\n",
    "    np.savez_compressed(output_path, boards=train_data[0], features=train_data[1], actions=train_data[2], rewards=train_data[3])\n",
    "    del state\n",
    "    del train_data\n",
    "    gc.collect()\n",
    "    log_ram_usage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.605284Z",
     "start_time": "2021-06-05T14:11:00.584894Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def create_train_data(agents, n_matches, reward_name, agent_idx_range=None):\n",
    "    \"\"\"\n",
    "    Creates train data without any simmetry\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    agents : list of str\n",
    "        Names or paths of the agents\n",
    "    n_matches : int\n",
    "        Number of matches to play\n",
    "    reward_name : str\n",
    "        Name of the reward function that we want to use\n",
    "    max_workers : int\n",
    "    agent_idx_range : list of int\n",
    "        Idx of the agents we want to use for collecting data, if None all the agents\n",
    "        will be used\n",
    "    \"\"\"\n",
    "    saved_games_path = get_games_output_path(agents, n_matches)\n",
    "    if not os.path.exists(saved_games_path):\n",
    "        play_matches_in_parallel_and_save_history(agents, n_matches=n_matches)\n",
    "\n",
    "    output_path = get_data_output_path(agents, n_matches, reward_name)\n",
    "    create_train_data_from_saved_matches([saved_games_path], reward_name, output_path, agent_idx_range=agent_idx_range)\n",
    "    \n",
    "def get_data_output_path(agents, n_matches, reward_name):\n",
    "    output_file = '/mnt/hdd0/Kaggle/hungry_geese/data/%s/%s_vs_%s_matches_%i.npz' % (\n",
    "        reward_name,\n",
    "        os.path.splitext(os.path.basename(agents[0]))[0], \n",
    "        os.path.splitext(os.path.basename(agents[1]))[0], \n",
    "        n_matches)\n",
    "    return output_file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.634624Z",
     "start_time": "2021-06-05T14:11:00.606973Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "initial_elo_ranking = pd.read_csv('../data/elo_ranking.csv', index_col='model')\n",
    "initial_elo_ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.656949Z",
     "start_time": "2021-06-05T14:11:00.635910Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "with open('../data/agents.yml', 'r') as f:\n",
    "    agents = yaml.safe_load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.680347Z",
     "start_time": "2021-06-05T14:11:00.657957Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def evaluate_agent(new_agent, adversary_agents, n_matches, single_agent=True, max_workers=20, run_agent_test=False):\n",
    "    agent_name = list(new_agent.keys())[0]\n",
    "    # I have found that for certain agents if the test is run then evaluation is frozen\n",
    "    if run_agent_test: test_agent(new_agent[agent_name])\n",
    "    reduced_agents_set = new_agent.copy()\n",
    "    for adversary_agent in adversary_agents:\n",
    "        reduced_agents_set[adversary_agent] = agents[adversary_agent]\n",
    "    \n",
    "    if single_agent:\n",
    "        sample_agents_func = lambda: [agent_name] + np.random.choice(adversary_agents, 3, replace=False).tolist()\n",
    "    else:\n",
    "        def sample_agents_func():\n",
    "            while 1:\n",
    "                sampled_agents = [agent_name] + np.random.choice(adversary_agents + [agent_name], 3).tolist()\n",
    "                if len(np.unique(sampled_agents)) >=2:\n",
    "                    break\n",
    "            return sampled_agents\n",
    "\n",
    "    matches_agents, matches_results = play_matches_in_parallel(reduced_agents_set, sample_agents_func, n_matches=n_matches, max_workers=max_workers)\n",
    "    return matches_agents, matches_results, reduced_agents_set\n",
    "    \n",
    "def compute_elo_ranking(matches_agents, matches_results, reduced_agents_set):\n",
    "    initial_agent_elo = 1000\n",
    "    for k in [32, 16, 8, 4, 2, 1]:\n",
    "        agent_name = [name for name in reduced_agents_set if name not in initial_elo_ranking][0]\n",
    "        initial_ranking = initial_elo_ranking.to_dict()['ranking']\n",
    "        initial_ranking[agent_name] = initial_agent_elo\n",
    "        initial_ranking = {key: initial_ranking[key] for key in reduced_agents_set}\n",
    "        elo_ranking = EloRanking(initial_ranking, {agent_name}, k=k)\n",
    "        for match_agents, match_results in zip(matches_agents, matches_results):\n",
    "            elo_ranking.add_match(match_agents, match_results)\n",
    "        initial_agent_elo = elo_ranking.summary().loc[agent_name, 'ranking']\n",
    "    elo_ranking.plot()\n",
    "    return elo_ranking.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.702116Z",
     "start_time": "2021-06-05T14:11:00.681485Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def simple_agent_evaluation(agent_path, n_matches=500):\n",
    "    \"\"\"\n",
    "    Computes single and multi agents scores and returns them\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    multi_agent_elo_score\n",
    "    single_agent_elo_score\n",
    "    \"\"\"\n",
    "    ret = evaluate_agent(\n",
    "        {'q_value_pretrained': agent_path},\n",
    "        initial_elo_ranking.index.values.tolist()[:5],\n",
    "        n_matches=n_matches, single_agent=False, max_workers=20)\n",
    "    table_multi = compute_elo_ranking(*ret)\n",
    "    ret = evaluate_agent(\n",
    "        {'q_value_pretrained': agent_path},\n",
    "        initial_elo_ranking.index.values.tolist()[:5],\n",
    "        n_matches=n_matches, single_agent=True, max_workers=20)\n",
    "    table_single = compute_elo_ranking(*ret)\n",
    "    plt.close('all')\n",
    "    clear_output()\n",
    "    print(agent_path)\n",
    "    print('Multi agent elo score: %i' % table_multi.loc['q_value_pretrained', 'ranking'])\n",
    "    print('Single agent elo score: %i' % table_single.loc['q_value_pretrained', 'ranking'])\n",
    "    return table_multi.loc['q_value_pretrained', 'ranking'], table_single.loc['q_value_pretrained', 'ranking']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.723311Z",
     "start_time": "2021-06-05T14:11:00.703454Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def simple_model_evaluation(model_path, n_matches=500):\n",
    "    model_path = os.path.realpath(model_path)\n",
    "    text = \"\"\"\n",
    "import os\n",
    "from hungry_geese.agents import QValueSemiSafeAgent\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import tensorflow as tf\n",
    "model = tf.keras.models.load_model('model_path', compile=False)\n",
    "q_value_agent = QValueSemiSafeAgent(model)\n",
    "def agent(obs, config):\n",
    "    return q_value_agent(obs, config)\n",
    "    \"\"\"\n",
    "    text = text.replace('model_path', model_path)\n",
    "    with tempfile.TemporaryDirectory() as tempdir:\n",
    "        agent_filepath = os.path.join(tempdir, 'agent.py')\n",
    "        with open(agent_filepath, 'w') as f:\n",
    "            f.write(text)\n",
    "        output = simple_agent_evaluation(agent_filepath, n_matches=n_matches)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.743071Z",
     "start_time": "2021-06-05T14:11:00.724410Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def plot_q_value(agent):\n",
    "    values = np.array(agent.q_values)\n",
    "    for idx in range(values.shape[1]):\n",
    "        plt.plot(values[:, idx], label=idx, alpha=0.6, marker='o')\n",
    "    plt.legend(loc=0)\n",
    "    plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.778560Z",
     "start_time": "2021-06-05T14:11:00.745411Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "COLOR_TO_INDEX = dict(white=0, blue=1, green=2, red=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.800296Z",
     "start_time": "2021-06-05T14:11:00.780077Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_html_game(agents, output_folder):\n",
    "    \"\"\"\n",
    "    Plays a game, saves to file and opens it on google chrome\n",
    "    \n",
    "    \n",
    "    Order of the agents\n",
    "    \n",
    "    - 0 white\n",
    "    - 1 blue\n",
    "    - 2 green\n",
    "    - 3 red\n",
    "    \"\"\"\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    env = make('hungry_geese')\n",
    "    ret = env.run(agents);\n",
    "    html_content = env.render(mode=\"html\")\n",
    "    filepath = os.path.join(output_folder, '%s.html' % get_timestamp())\n",
    "    with open(filepath, 'w') as f:\n",
    "        f.write(html_content)\n",
    "    print(filepath)\n",
    "    os.system('google-chrome \"%s\"' % os.path.realpath(filepath))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.821395Z",
     "start_time": "2021-06-05T14:11:00.801432Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def save_html_games(agents, output_folder, n_games=10):\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "    env = make('hungry_geese')\n",
    "    for game_idx in tqdm(range(n_games)):\n",
    "        ret = env.run(agents);\n",
    "        html_content = env.render(mode=\"html\")\n",
    "        filepath = os.path.join(output_folder, '%02d.html' % game_idx)\n",
    "        with open(filepath, 'w') as f:\n",
    "            f.write(html_content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Bug fix agent change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T04:39:10.442374Z",
     "start_time": "2021-05-10T04:35:23.442171Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# with the bug\n",
    "simple_model_evaluation('/mnt/hdd0/Kaggle/hungry_geese/models/38_great_redesign_debug/11_discount_factor_1_epsilon_greedy_01/epoch_5200.h5', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T04:35:01.157120Z",
     "start_time": "2021-05-10T04:31:10.156137Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# after fixing the bug\n",
    "simple_model_evaluation('/mnt/hdd0/Kaggle/hungry_geese/models/38_great_redesign_debug/11_discount_factor_1_epsilon_greedy_01/epoch_5200.h5', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T05:32:36.762628Z",
     "start_time": "2021-05-10T05:28:50.785717Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# after fixing the bug and fixing the agents\n",
    "simple_model_evaluation('/mnt/hdd0/Kaggle/hungry_geese/models/38_great_redesign_debug/11_discount_factor_1_epsilon_greedy_01/epoch_5200.h5', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T05:27:02.215412Z",
     "start_time": "2021-05-10T05:23:10.155305Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "# after fixing the bug and fixing the agents, and reevaluating the agents\n",
    "simple_model_evaluation('/mnt/hdd0/Kaggle/hungry_geese/models/38_great_redesign_debug/11_discount_factor_1_epsilon_greedy_01/epoch_5200.h5', n_matches=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Reevaluate frozen agents"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "hidden": true
   },
   "source": [
    "rhaegar,1612\n",
    "balerion,1565"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T04:42:52.751247Z",
     "start_time": "2021-05-10T04:40:58.263643Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/data/agents/clasic.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T04:46:18.583513Z",
     "start_time": "2021-05-10T04:44:00.898518Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/data/agents/ram.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T04:49:25.779967Z",
     "start_time": "2021-05-10T04:46:52.062226Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/data/agents/wallbreaker.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T04:52:49.235517Z",
     "start_time": "2021-05-10T04:49:54.356974Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/data/agents/iceberg.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T04:56:51.455712Z",
     "start_time": "2021-05-10T04:53:29.559899Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/data/agents/icedragon.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T05:01:02.809135Z",
     "start_time": "2021-05-10T04:57:27.845152Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/data/agents/balerion.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-10T05:22:12.420638Z",
     "start_time": "2021-05-10T05:18:22.368932Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/data/agents/rhaegar.py')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-01T07:47:06.267489Z",
     "start_time": "2021-05-01T07:46:15.210462Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New agents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T09:14:31.639949Z",
     "start_time": "2021-05-18T09:10:38.707297Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_model_evaluation('/mnt/hdd0/Kaggle/hungry_geese/models/40_study_effect_of_epsilon/04_epsilon_greedy_001/epoch_7920.h5', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T09:53:03.753215Z",
     "start_time": "2021-05-18T09:48:46.637327Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/gargantua.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T09:59:29.477227Z",
     "start_time": "2021-05-18T09:53:03.755842Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/gargantua_data_augmentation.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T14:25:42.537811Z",
     "start_time": "2021-05-21T14:21:10.305277Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/obelix.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-21T14:33:01.839806Z",
     "start_time": "2021-05-21T14:26:13.970943Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/obelix_data_augmentation.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Is strange that in this case data augmented agent gets a worse result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:43:48.933495Z",
     "start_time": "2021-05-25T14:37:40.473016Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/arnold.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:53:49.377980Z",
     "start_time": "2021-05-25T14:43:48.934769Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/arnold_data_augmentation.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T06:18:09.436434Z",
     "start_time": "2021-05-28T06:10:01.052471Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/sylvester.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-28T06:31:08.958834Z",
     "start_time": "2021-05-28T06:18:09.439235Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/sylvester_data_augmentation.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm struggling to get as good scores as gargantua, even it it seems that this new models are better. I think reward may play a role because when the end of the match is achieved I'm not currently given different reward for a different position.\n",
    "\n",
    "Let's try with an smaller model that uses 128 units instead of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T05:28:28.221242Z",
     "start_time": "2021-05-31T05:23:31.981688Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/jagger.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-31T05:36:11.222370Z",
     "start_time": "2021-05-31T05:28:28.223822Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/jagger_data_augmentation.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T10:36:41.595463Z",
     "start_time": "2021-06-01T10:18:08.723188Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/decurion.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-01T11:11:08.400732Z",
     "start_time": "2021-06-01T10:36:41.598690Z"
    },
    "deletable": false,
    "editable": false,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/scripts/q_value_submission/decurion_data_augmentation.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Visualizing agent play"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "### 40_study_effect_of_epsilon/04_epsilon_greedy_001"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T09:30:19.729767Z",
     "start_time": "2021-05-18T09:30:16.409630Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/mnt/hdd0/Kaggle/hungry_geese/models/40_study_effect_of_epsilon/04_epsilon_greedy_001/epoch_7920.h5', compile=False)\n",
    "agents = [QValueSemiSafeAgent(model) for idx in range(4)]\n",
    "\n",
    "[agent.reset() for agent in agents]; save_html_game(agents, '../data/saved_games/06_semi_safe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "The level of playing is really good. I like seeing this matches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T09:24:37.466493Z",
     "start_time": "2021-05-18T09:24:37.428894Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "agents[COLOR_TO_INDEX['red']].q_values[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T09:28:09.406921Z",
     "start_time": "2021-05-18T09:28:09.361268Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "np.array(agents[COLOR_TO_INDEX['green']].q_values)[24]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T09:27:03.341820Z",
     "start_time": "2021-05-18T09:27:03.149020Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "plot_q_value(agents[COLOR_TO_INDEX['green']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Let's also play against the frozen agents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-18T09:36:50.201060Z",
     "start_time": "2021-05-18T09:36:47.278469Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "[agent.reset() for agent in agents]; save_html_game(agents[:1] + ['../data/agents/rhaegar.py', '../data/agents/balerion.py', '../data/agents/icedragon.py'], '../data/saved_games/06_semi_safe')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study train data to create new metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial goal was to create new metrics that will allow to better understand the behaviour of the agent. However I have found some evidences of problems with the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.842833Z",
     "start_time": "2021-06-05T14:11:00.822568Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def match_duration_histogram(data):\n",
    "    terminal_idx = get_terminal_indices(data)\n",
    "    match_durations = get_match_durations(terminal_idx)\n",
    "    plt.hist(match_durations, bins=np.linspace(0, 200, 20))\n",
    "    plt.title('Histogram of match duration (%i matches)' % len(match_durations))\n",
    "    plt.xlabel('steps')\n",
    "    print('Mean match duration', np.mean(match_durations))\n",
    "    \n",
    "def get_terminal_indices(data):\n",
    "    \"\"\" Returns the indices of the states that are terminal \"\"\"\n",
    "    terminal_idx = np.arange(len(data['is_not_terminal']))[np.sum(data['is_not_terminal'], axis=1) == 0]\n",
    "    return terminal_idx\n",
    "\n",
    "def get_match_durations(terminal_idx):\n",
    "    match_durations = terminal_idx.copy()\n",
    "    match_durations[1:] -= match_durations[:-1]\n",
    "    return match_durations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.864811Z",
     "start_time": "2021-06-05T14:11:00.843936Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def reward_vs_step_plot(data, jitter=0):\n",
    "    terminal_idx = get_terminal_indices(data)\n",
    "    match_durations = get_match_durations(terminal_idx)\n",
    "    terminal_rewards = []\n",
    "    for rewards, mask in zip(data['rewards'][terminal_idx], data['training_mask'][terminal_idx]):\n",
    "        terminal_rewards.append(rewards[mask == 1])\n",
    "    terminal_rewards = [max(rewards) for rewards in terminal_rewards]\n",
    "    np.random.seed(8)\n",
    "    plt.scatter(add_jitter(match_durations, jitter), terminal_rewards, alpha=0.6);\n",
    "    plt.xlabel('step')\n",
    "    plt.ylabel('reward')\n",
    "    plt.grid(axis='y')\n",
    "    \n",
    "def add_jitter(x, jitter):\n",
    "    x = np.array(x)\n",
    "    return x + np.random.normal(0, jitter, x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.886758Z",
     "start_time": "2021-06-05T14:11:00.866256Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def terminal_reward_histogram(data):\n",
    "    terminal_rewards = get_terminal_reward(data)\n",
    "    plt.hist(terminal_rewards)\n",
    "\n",
    "def terminal_reward_dataframe(data):\n",
    "    terminal_rewards = get_terminal_reward(data)\n",
    "    values, counts = np.unique(terminal_rewards, return_counts=True)\n",
    "    df = pd.DataFrame(dict(counts=counts), index=values)\n",
    "    df.index.name = 'reward'\n",
    "    return df\n",
    "\n",
    "def get_terminal_reward(data):\n",
    "    terminal_idx = get_terminal_indices(data)\n",
    "    match_durations = get_match_durations(terminal_idx)\n",
    "    terminal_rewards = []\n",
    "    for rewards, mask in zip(data['rewards'][terminal_idx], data['training_mask'][terminal_idx]):\n",
    "        terminal_rewards.append(rewards[mask == 1])\n",
    "    terminal_rewards = [max(rewards) for rewards in terminal_rewards]\n",
    "    return terminal_rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:11:00.906741Z",
     "start_time": "2021-06-05T14:11:00.887880Z"
    },
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def explore_train_data(filepath):\n",
    "    data = dict(**np.load(filepath))\n",
    "    print(data.keys())\n",
    "    match_duration_histogram(data); plt.show()\n",
    "    reward_vs_step_plot(data, jitter=0.2); plt.show()\n",
    "    return terminal_reward_dataframe(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:41:40.125420Z",
     "start_time": "2021-06-05T14:41:40.081500Z"
    },
    "code_folding": [],
    "hidden": true
   },
   "outputs": [],
   "source": [
    "def visualize_match(filepath, match_idx, model=None):\n",
    "    \"\"\"\n",
    "    Plots a visualization of the match\n",
    "    On the title shows the reward for that state\n",
    "    If a model is given it shows the prediction for that state\n",
    "    If a model is not give shows the training mask, and is_not_terminal \n",
    "    \"\"\"\n",
    "    data = dict(**np.load(filepath))\n",
    "    _visualize_match(data, match_idx, model=model)\n",
    "    \n",
    "def _visualize_match(data, match_idx, model, n_cols=10, ):\n",
    "    start, end = _get_match_start_and_end(data, match_idx)\n",
    "    game_state = GameState()\n",
    "    for plot_idx, step_idx in enumerate(range(start, end)):\n",
    "        if not plot_idx % n_cols: plt.show()\n",
    "        plt.subplot(1, n_cols, plot_idx%n_cols + 1)\n",
    "        plt.imshow(game_state.render_board(data['boards'][step_idx]))\n",
    "        plt.xticks([]); plt.yticks([])\n",
    "        plt.title(data['rewards'][step_idx])\n",
    "        plt.ylabel(plot_idx)\n",
    "        if model is not None:\n",
    "            action_value = _predict_action_value(model, data, step_idx)\n",
    "            plt.xlabel(str(action_value.round(1)))\n",
    "        else:\n",
    "            plt.xlabel(str(data['training_mask'][step_idx]) + ' ' + str(data['is_not_terminal'][step_idx]))\n",
    "        \n",
    "def _get_match_start_and_end(data, match_idx):\n",
    "    terminal_idx = get_terminal_indices(data)\n",
    "    end = terminal_idx[match_idx] + 1\n",
    "    if match_idx:\n",
    "        start = terminal_idx[match_idx - 1] + 1\n",
    "    else:\n",
    "        start = 0\n",
    "    return start, end\n",
    "\n",
    "def _predict_action_value(model, data, step_idx):\n",
    "    model_input = [data['boards'][step_idx:step_idx+1], data['features'][step_idx:step_idx+1]]\n",
    "    return model.predict_step(model_input)[0].numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### First explorations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:35:57.930046Z",
     "start_time": "2021-05-25T14:35:57.491409Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "explore_train_data('/mnt/hdd0/Kaggle/hungry_geese/models/39_more_trains_after_bugfix/02_epsilon_greedy_01_discount_factor_1/epoch_1182.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:35:58.269395Z",
     "start_time": "2021-05-25T14:35:57.931447Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "explore_train_data('/mnt/hdd0/Kaggle/hungry_geese/models/39_more_trains_after_bugfix/02_epsilon_greedy_01_discount_factor_1/epoch_5200.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "Most of the rewards still -5 after 4000 epochs, how that can be?\n",
    "\n",
    "- Visualize games: state, q_value and target\n",
    "- target vs q_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "### Match visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:35:58.475854Z",
     "start_time": "2021-05-25T14:35:58.271727Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/mnt/hdd0/Kaggle/hungry_geese/models/39_more_trains_after_bugfix/02_epsilon_greedy_01_discount_factor_1/epoch_1181.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:35:58.615873Z",
     "start_time": "2021-05-25T14:35:58.478443Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/mnt/hdd0/Kaggle/hungry_geese/models/39_more_trains_after_bugfix/02_epsilon_greedy_01_discount_factor_1/epoch_5199.h5', compile=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:36:03.954276Z",
     "start_time": "2021-05-25T14:35:58.617418Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "visualize_match('/mnt/hdd0/Kaggle/hungry_geese/models/39_more_trains_after_bugfix/02_epsilon_greedy_01_discount_factor_1/epoch_5200.npz', 2, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:36:08.099330Z",
     "start_time": "2021-05-25T14:36:03.955460Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "visualize_match('/mnt/hdd0/Kaggle/hungry_geese/models/39_more_trains_after_bugfix/02_epsilon_greedy_01_discount_factor_1/epoch_1182.npz', 3, model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-05-25T14:36:08.184737Z",
     "start_time": "2021-05-25T14:36:08.101879Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/mnt/hdd0/Kaggle/hungry_geese/models/39_more_trains_after_bugfix/02_epsilon_greedy_01_discount_factor_1/epoch_1181.h5', compile=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "hidden": true
   },
   "source": [
    "I have the feeling that many of the deaths are caused by the epsilon greedy policy, I'm going to decrease epsilon and compare."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Study game data after improving certain death reward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:54:05.714201Z",
     "start_time": "2021-06-05T14:54:01.591704Z"
    }
   },
   "outputs": [],
   "source": [
    "visualize_match('/mnt/hdd0/Kaggle/hungry_geese/models/46_train_from_zero_on/01_first_steps/debug2.npz', 1, model=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-06-05T14:30:52.204140Z",
     "start_time": "2021-06-05T14:30:51.904191Z"
    }
   },
   "outputs": [],
   "source": [
    "explore_train_data('/mnt/hdd0/Kaggle/hungry_geese/models/46_train_from_zero_on/01_first_steps/debug2.npz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "heading_collapsed": true
   },
   "source": [
    "## Useful snippets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_model_evaluation('/mnt/hdd0/Kaggle/hungry_geese/models/32_automated_iteration/13_continue_with_smaller_lr/epoch_0447.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "simple_agent_evaluation('/mnt/hdd0/MEGA/AI/22 Kaggle/hungry_geese/data/agents/wallbreaker_data_augmentation.py', n_matches=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "model = keras.models.load_model('/mnt/hdd0/Kaggle/hungry_geese/models/32_automated_iteration/11_continue_with_scale_8/epoch_0347.h5', compile=False)\n",
    "model = tf.keras.models.Model(inputs=model.inputs[:2], outputs=model.layers[-3].output)\n",
    "agents = [QValueAgent(model) for idx in range(4)]\n",
    "\n",
    "[agent.reset() for agent in agents]; save_html_game(agents, '../data/saved_games/03_clip_len_reward_analysis')\n",
    "plot_q_value(agents[COLOR_TO_INDEX['white']]); plt.xlim(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2021-03-23T13:38:12.980Z"
    },
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "agent_base = '../data/agents/quantum/epsilon_quantum_010.py'\n",
    "best_5_agents = [agents[name] for name in initial_elo_ranking.index.values[:4]]\n",
    "best_5_agents += ['/mnt/hdd0/Kaggle/hungry_geese/models/25_ladder_of_agents/04_epsilon010_vs_best5_reward_-4_4_x128_80000_pretrained/q_value_agent.py']\n",
    "sampling_agent_func = lambda: [agent_base] + np.random.choice(best_5_agents, 3).tolist()\n",
    "\n",
    "for n_matches in [8000, 39000, 40000]:\n",
    "    output_path = '/mnt/hdd0/Kaggle/hungry_geese/games/%s_vs_best5_it2_matches_%i.json' % (os.path.splitext(os.path.basename(agent_base))[0], n_matches)\n",
    "    play_matches_in_parallel_and_save_history(agents=sampling_agent_func, n_matches=n_matches, output_path=output_path)\n",
    "    \n",
    "reward_name = 'ranking_reward_-4_4'\n",
    "\n",
    "saved_games_paths = ['/mnt/hdd0/Kaggle/hungry_geese/games/%s_vs_best5_it2_matches_%i.json' % (os.path.splitext(os.path.basename(agent_base))[0], n_matches) for n_matches in [8000]]\n",
    "output_path = '/mnt/hdd0/Kaggle/hungry_geese/data/%s/%s_vs_best5_it2_matches_%i.npz' % (reward_name, os.path.splitext(os.path.basename(agent_base))[0], 8000)\n",
    "create_train_data_from_saved_matches(saved_games_paths, reward_name, output_path, agent_idx_range=[0])\n",
    "\n",
    "saved_games_paths = ['/mnt/hdd0/Kaggle/hungry_geese/games/%s_vs_best5_it2_matches_%i.json' % (os.path.splitext(os.path.basename(agent_base))[0], n_matches) for n_matches in [39000, 40000]]\n",
    "output_path = '/mnt/hdd0/Kaggle/hungry_geese/data/%s/%s_vs_best5_it2_matches_%i.npz' % (reward_name, os.path.splitext(os.path.basename(agent_base))[0], 80000)\n",
    "create_train_data_from_saved_matches(saved_games_paths, reward_name, output_path, agent_idx_range=[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "agent_names = initial_elo_ranking.index.values.tolist()[:4]\n",
    "output_folder = '../data/saved_games/02_quantum'\n",
    "save_html_games([agents[name] for name in agent_names], output_folder, n_games=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "ret = evaluate_agent(\n",
    "    {'q_value_pretrained': '/mnt/hdd0/Kaggle/hungry_geese/models/25_ladder_of_agents/01_epsilon025_reward_-4_4_x128_30000_pretrained/q_value_agent.py'},\n",
    "    initial_elo_ranking.index.values.tolist()[:5],\n",
    "    n_matches=500, single_agent=False, max_workers=20)\n",
    "compute_elo_ranking(*ret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "editable": false,
    "hidden": true,
    "run_control": {
     "frozen": true
    }
   },
   "outputs": [],
   "source": [
    "agent_filepaths = sorted(glob.glob('/mnt/hdd0/Kaggle/hungry_geese/models/28_architecture_study/*/q_value_agent.py'))\n",
    "print(agent_filepaths)\n",
    "df = pd.DataFrame()\n",
    "for agent_filepath in agent_filepaths:\n",
    "    print(df)\n",
    "    ret = simple_agent_evaluation(agent_filepath, n_matches=500)\n",
    "    name = os.path.basename(os.path.dirname(agent_filepath))\n",
    "    df.loc[name, 'multi'] = ret[0]\n",
    "    df.loc[name, 'single'] = ret[1]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python (goose)",
   "language": "python",
   "name": "goose"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "769px",
    "left": "80px",
    "top": "159px",
    "width": "222.594px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
